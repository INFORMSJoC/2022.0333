{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.009745359420776367,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 2000,
       "unit": "ex",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705a1872016d4d82b8684d3a85b778b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2000 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['label', 'input'],\n",
       "     num_rows: 1700\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['label', 'input'],\n",
       "     num_rows: 300\n",
       " }))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "data = pd.read_csv(\"Data/dataset.csv\", header=None)\n",
    "data.columns = [\"input1\", \"input2\", \"input3\", \"label\"]\n",
    "\n",
    "def preprocess(example):\n",
    "    input1 = example['input1'] if example['input1'] else \"\"\n",
    "    input2 = example['input2'] if example['input2'] else \"\"\n",
    "    \n",
    "    return {\n",
    "        \"input\": input1 + input2\n",
    "    }\n",
    "\n",
    "dataset = Dataset.from_pandas(data)\n",
    "dataset = dataset.map(preprocess)\n",
    "dataset = dataset.remove_columns(column_names=[\"input1\", \"input2\", \"input3\"])\n",
    "\n",
    "dataset = dataset.train_test_split(test_size=0.15)\n",
    "train_set, test_set = dataset['train'], dataset['test']\n",
    "\n",
    "train_set, test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at /datas/zyq/personal/D6791/xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.weight', 'lm_loss.bias']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2Model, XLNetTokenizer, XLNetModel\n",
    "\n",
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(\"/Data/model/gpt2\")\n",
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained(\"/Data/model/xlnet-base-cased\")\n",
    "\n",
    "gpt2 = GPT2Model.from_pretrained(\"/Data/model/gpt2\")\n",
    "xlnet = XLNetModel.from_pretrained(\"/Data/model/xlnet-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n",
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.vocab import GloVe, Vectors\n",
    "import fasttext\n",
    "import os\n",
    "\n",
    "cbow = fasttext.load_model('/Data/model/cbow/cc.en.300.bin')\n",
    "skip_gram = fasttext.load_model(\"/Data/model/skipgram/wiki.en.bin\")\n",
    "glove = GloVe(name='6B', dim=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, num_classes: int):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.gpt_embedding = gpt2.wte.half()\n",
    "        self.xlnet_embedding = xlnet.word_embedding.half()\n",
    "\n",
    "        # glove = GloVe(name='6B', dim=300)\n",
    "        self.glove_embedding = nn.Embedding.from_pretrained(glove.vectors, freeze=False).half()\n",
    "        \n",
    "        self.cbow_embedding = nn.Embedding.from_pretrained(torch.from_numpy(cbow.get_input_matrix()), freeze=False).half()\n",
    "\n",
    "        self.skipgram_embedding = nn.Embedding.from_pretrained(torch.from_numpy(skip_gram.get_input_matrix()), freeze=False).half()\n",
    "\n",
    "        self.linear = nn.Linear(\n",
    "            self.xlnet_embedding.embedding_dim + self.gpt_embedding.embedding_dim + self.glove_embedding.embedding_dim + self.cbow_embedding.embedding_dim + self.skipgram_embedding.embedding_dim, \n",
    "            num_classes\n",
    "        ).half()\n",
    "\n",
    "    def forward(self, x_gpt, x_xlnet, x_glove, x_cbow):\n",
    "        gpt_emb = self.gpt_embedding(x_gpt)\n",
    "        xlnet_emb = self.xlnet_embedding(x_xlnet)\n",
    "        glove_emb = self.glove_embedding(x_glove)\n",
    "        cbow_emb = self.cbow_embedding(x_cbow)\n",
    "        skipgram_emb = self.skipgram_embedding(x_cbow)\n",
    "\n",
    "        gpt_emb_mean = torch.mean(gpt_emb, dim=1)\n",
    "        xlnet_emb_mean = torch.mean(xlnet_emb, dim=1)\n",
    "        glove_emb_mean = torch.mean(glove_emb, dim = 1)\n",
    "        cbow_emb_mean = torch.mean(cbow_emb, dim = 1)\n",
    "        skipgram_emb_mean = torch.mean(skipgram_emb, dim = 1)\n",
    "\n",
    "        merge_emb = torch.concat([gpt_emb_mean, xlnet_emb_mean, glove_emb_mean, cbow_emb_mean, skipgram_emb_mean], dim=1)\n",
    "        \n",
    "        output = self.linear(merge_emb)\n",
    "        \n",
    "        # output = nn.Softmax(output)\n",
    "\n",
    "        return output\n",
    "    \n",
    "model = CustomModel(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import get_tokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def tokenizer(input, stoi):\n",
    "    output = []\n",
    "    for data in input:\n",
    "        if data in stoi.keys():\n",
    "            output.append(stoi[data])\n",
    "        else:\n",
    "            output.append(0)\n",
    "            \n",
    "    return torch.tensor(output)\n",
    "\n",
    "def cbow_tokenize(ft, input):\n",
    "    input = fasttext.tokenize(input)\n",
    "    output = []\n",
    "    for data in input:\n",
    "        output.append(\n",
    "            ft.get_word_id(data)\n",
    "        )\n",
    "    output = [0 if d == -1 else d for d in output]\n",
    "    return torch.tensor(output)\n",
    "\n",
    "def collate_fn(example):\n",
    "    input = [data['input'] for data in example]\n",
    "    label = [data['label'] for data in example]\n",
    "\n",
    "    encode1 = gpt2_tokenizer(input, return_tensors='pt', padding=True)\n",
    "    \n",
    "    encode2 = xlnet_tokenizer(input, return_tensors='pt', padding=True)\n",
    "\n",
    "    encode3 = [tokenizer(glove_tokenizer(data), glove.stoi) for data in input]\n",
    "    encode3 = pad_sequence(encode3, batch_first=True)\n",
    "\n",
    "    encode4 = [cbow_tokenize(cbow, data) for data in input]\n",
    "    encode4 = pad_sequence(encode4, batch_first=True)\n",
    "    \n",
    "    return encode1, encode2, encode3, encode4, torch.LongTensor(label)\n",
    "\n",
    "\n",
    "glove_tokenizer = get_tokenizer('basic_english')\n",
    "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token\n",
    "glove_tokenizer = get_tokenizer('basic_english')\n",
    "\n",
    "# ft\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=2, shuffle=True, collate_fn=collate_fn)\n",
    "valid_loader = DataLoader(test_set, batch_size=2, shuffle=False, collate_fn=collate_fn, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, f1_score, recall_score, precision_score\n",
    "\n",
    "class AvgMetric:\n",
    "    def __init__(self):\n",
    "        self.total = 0.0\n",
    "        self.count = 0\n",
    "    \n",
    "    def update(self, value):\n",
    "        self.total += value\n",
    "        self.count += 1\n",
    "    \n",
    "    def reset(self):\n",
    "        self.total = 0.0\n",
    "        self.count = 0\n",
    "    \n",
    "    def compute(self):\n",
    "        if self.count == 0:\n",
    "            return None\n",
    "        return self.total / self.count\n",
    "    \n",
    "roc = AvgMetric()\n",
    "f1 = AvgMetric()\n",
    "recall = AvgMetric()\n",
    "precision = AvgMetric()\n",
    "loss_train = AvgMetric()\n",
    "loss_test = AvgMetric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.010207414627075195,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 8500,
       "unit": "it",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2da9b1dc86d846e1a63d8388c3117ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 2, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 2, 2, 2, 2, 0, 0, 0, 0, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2, 2, 0, 0, 0, 0, 0, 2, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 2, 2, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0]\n",
      "[2, 2, 0, 0, 0, 0, 2, 0, 0, 1, 0, 2, 0, 0, 0, 1, 1, 0, 2, 1, 2, 2, 2, 1, 0, 2, 0, 0, 0, 1, 2, 0, 0, 0, 2, 2, 2, 0, 0, 2, 1, 2, 0, 0, 2, 1, 0, 0, 1, 0, 2, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 2, 1, 0, 0, 1, 0, 1, 0, 1, 2, 1, 2, 1, 2, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 2, 2, 2, 0, 0, 1, 2, 0, 2, 0, 1, 1, 0, 0, 1, 0, 0, 0, 2, 2, 0, 0, 0, 0, 1, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 2, 0, 0, 2, 0, 2, 0, 0, 2, 0, 2, 0, 0, 0, 2, 2, 2, 0, 0, 1, 2, 2, 2, 2, 0, 0, 0, 0, 0, 2, 1, 0, 2, 2, 2, 2, 2, 0, 0, 2, 2, 0, 2, 2, 1, 0, 1, 2, 2, 0, 1, 0, 0, 2, 2, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 1, 0, 2, 0, 0, 0, 1, 0, 2, 2, 0, 0, 0, 1, 2, 2, 2, 0, 0, 1, 2, 2, 0, 0, 1, 0, 2, 2, 2, 0, 0, 2, 2, 1, 1, 0, 0, 0, 2, 0, 1, 0, 0, 0, 2, 0, 1, 0, 0, 1, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 2, 1, 0, 0, 2, 0, 0, 2, 2, 0, 0, 0, 2, 2, 0, 1, 2, 0, 2, 0, 0, 0, 0, 1, 2, 0, 0, 1, 0, 0, 2, 2, 2, 0, 0]\n",
      "[array([8.11523438e-01, 2.38418579e-07, 1.88476562e-01]), array([5.55664062e-01, 5.07235527e-05, 4.44091797e-01]), array([5.65917969e-01, 5.57303429e-05, 4.33837891e-01]), array([9.07226562e-01, 6.37769699e-06, 9.28955078e-02]), array([0.24401855, 0.        , 0.75585938]), array([0.92578125, 0.        , 0.07434082]), array([9.19921875e-01, 5.96046448e-08, 8.00170898e-02]), array([9.99023438e-01, 3.39746475e-06, 1.12247467e-03]), array([5.62500000e-01, 2.56299973e-04, 4.37255859e-01]), array([0.91113281, 0.        , 0.08880615]), array([6.12304688e-01, 2.68220901e-06, 3.87695312e-01]), array([4.85351562e-01, 4.17232513e-07, 5.14648438e-01]), array([0.60986328, 0.00186634, 0.38818359]), array([4.23828125e-01, 5.22136688e-04, 5.75683594e-01]), array([0.91064453, 0.        , 0.08959961]), array([9.32128906e-01, 5.28097153e-05, 6.79321289e-02]), array([8.14941406e-01, 2.81810760e-04, 1.84692383e-01]), array([0.92480469, 0.        , 0.07525635]), array([6.81640625e-01, 2.03490257e-04, 3.18115234e-01]), array([8.49121094e-01, 7.71284103e-05, 1.51000977e-01]), array([5.27343750e-01, 5.96046448e-08, 4.72656250e-01]), array([0.68505859, 0.        , 0.31494141]), array([3.96972656e-01, 4.84466553e-04, 6.02539062e-01]), array([0.96826172, 0.        , 0.03158569]), array([9.81933594e-01, 1.78813934e-06, 1.80969238e-02]), array([8.98437500e-01, 1.78813934e-07, 1.01684570e-01]), array([4.41650391e-01, 1.23500824e-04, 5.58105469e-01]), array([9.11132812e-01, 3.33786011e-06, 8.88061523e-02]), array([6.33789062e-01, 6.91413879e-06, 3.65966797e-01]), array([0.45043945, 0.00167561, 0.54785156]), array([0.86425781, 0.        , 0.13586426]), array([0.61865234, 0.00679779, 0.37451172]), array([1.85791016e-01, 1.78813934e-07, 8.13964844e-01]), array([0.72265625, 0.00393295, 0.27319336]), array([0.99511719, 0.        , 0.00471878]), array([1.88903809e-02, 5.96046448e-08, 9.80957031e-01]), array([5.67871094e-01, 1.39594078e-04, 4.32128906e-01]), array([5.21484375e-01, 6.55651093e-07, 4.78515625e-01]), array([0.88525391, 0.        , 0.1149292 ]), array([5.50292969e-01, 4.01973724e-04, 4.49462891e-01]), array([0.53662109, 0.00156498, 0.46166992]), array([4.33349609e-01, 3.57627869e-07, 5.66406250e-01]), array([0.71142578, 0.00088024, 0.2878418 ]), array([9.20898438e-01, 7.80820847e-06, 7.91625977e-02]), array([0.66113281, 0.00113773, 0.33789062]), array([0.4230957 , 0.27832031, 0.29858398]), array([8.03710938e-01, 2.38418579e-07, 1.96411133e-01]), array([9.83398438e-01, 1.49011612e-06, 1.66015625e-02]), array([0.80615234, 0.00202179, 0.19189453]), array([6.06445312e-01, 2.24709511e-05, 3.93798828e-01]), array([0.7421875 , 0.00281143, 0.25512695]), array([6.29394531e-01, 1.18613243e-05, 3.70605469e-01]), array([0.88964844, 0.        , 0.11010742]), array([5.22949219e-01, 4.79221344e-04, 4.76562500e-01]), array([8.99414062e-01, 2.44379044e-06, 1.00463867e-01]), array([5.24414062e-01, 2.38418579e-06, 4.75341797e-01]), array([9.32128906e-01, 1.25169754e-06, 6.81152344e-02]), array([0.62646484, 0.00073051, 0.37304688]), array([0.42871094, 0.00227165, 0.56884766]), array([0.55029297, 0.00138378, 0.44848633]), array([7.66601562e-01, 2.42710114e-04, 2.33032227e-01]), array([6.72851562e-01, 8.94069672e-07, 3.27392578e-01]), array([0.54003906, 0.00147533, 0.45849609]), array([8.26660156e-01, 2.86102295e-06, 1.73095703e-01]), array([0.92480469, 0.        , 0.07519531]), array([0.68798828, 0.01277924, 0.29907227]), array([8.56445312e-01, 1.25169754e-05, 1.43310547e-01]), array([0.97998047, 0.00107193, 0.01895142]), array([9.97558594e-01, 2.38418579e-07, 2.22206116e-03]), array([0.98925781, 0.        , 0.01085663]), array([0.30615234, 0.        , 0.69384766]), array([0.83691406, 0.00098705, 0.1619873 ]), array([5.13671875e-01, 1.25169754e-06, 4.86083984e-01]), array([9.90234375e-01, 4.82559204e-04, 9.09423828e-03]), array([0.99121094, 0.        , 0.00882721]), array([3.54736328e-01, 3.93390656e-06, 6.45507812e-01]), array([0.76660156, 0.00124359, 0.23205566]), array([6.32812500e-01, 2.12788582e-05, 3.67431641e-01]), array([9.92187500e-01, 1.78813934e-06, 7.91931152e-03]), array([9.28710938e-01, 1.19209290e-07, 7.12280273e-02]), array([4.68505859e-01, 1.43051147e-06, 5.31738281e-01]), array([0.2824707 , 0.        , 0.71728516]), array([0.97558594, 0.        , 0.0242157 ]), array([3.73046875e-01, 5.96046448e-08, 6.26953125e-01]), array([4.96337891e-01, 9.62615013e-05, 5.03417969e-01]), array([7.27050781e-01, 1.67012215e-04, 2.72949219e-01]), array([9.96582031e-01, 5.96046448e-08, 3.36265564e-03]), array([8.87207031e-01, 1.56164169e-04, 1.12670898e-01]), array([0.66650391, 0.        , 0.33325195]), array([7.78808594e-01, 2.40206718e-05, 2.21313477e-01]), array([1.06201172e-01, 3.98159027e-05, 8.93554688e-01]), array([1.00000000e+00, 0.00000000e+00, 1.51753426e-04]), array([4.47753906e-01, 6.74128532e-05, 5.52246094e-01]), array([2.60498047e-01, 1.19209290e-07, 7.39257812e-01]), array([2.94433594e-01, 5.96046448e-08, 7.05566406e-01]), array([8.34472656e-01, 5.96046448e-08, 1.65649414e-01]), array([6.03027344e-01, 5.96046448e-08, 3.97216797e-01]), array([3.89892578e-01, 7.74860382e-06, 6.09863281e-01]), array([6.78710938e-01, 3.34382057e-05, 3.21289062e-01]), array([0.32641602, 0.00403214, 0.66943359]), array([9.02343750e-01, 2.86102295e-06, 9.74731445e-02]), array([5.98144531e-01, 1.19209290e-07, 4.01855469e-01]), array([0.56054688, 0.00405121, 0.43530273]), array([7.33398438e-01, 4.16517258e-04, 2.65869141e-01]), array([0.88964844, 0.        , 0.11053467]), array([6.26953125e-01, 5.96046448e-08, 3.73046875e-01]), array([4.99755859e-01, 2.80141830e-06, 5.00000000e-01]), array([0.58056641, 0.00071383, 0.41870117]), array([0.98193359, 0.        , 0.01818848]), array([5.25390625e-01, 1.01327896e-06, 4.74609375e-01]), array([1.25610352e-01, 2.27689743e-05, 8.74511719e-01]), array([0.98242188, 0.        , 0.01757812]), array([5.57128906e-01, 8.17775726e-05, 4.42626953e-01]), array([4.65087891e-01, 1.79648399e-04, 5.34667969e-01]), array([0.63476562, 0.        , 0.36523438]), array([9.23828125e-01, 1.48415565e-05, 7.59887695e-02]), array([0.92138672, 0.        , 0.07849121]), array([5.33447266e-02, 1.03712082e-05, 9.46777344e-01]), array([7.18261719e-01, 1.66893005e-06, 2.81738281e-01]), array([4.81933594e-01, 1.07288361e-06, 5.18066406e-01]), array([7.78320312e-01, 8.34465027e-07, 2.21557617e-01]), array([0.08648682, 0.        , 0.91357422]), array([2.38647461e-01, 5.49554825e-05, 7.61230469e-01]), array([4.90478516e-01, 6.19888306e-06, 5.09277344e-01]), array([8.31054688e-01, 2.72035599e-04, 1.68823242e-01]), array([7.09472656e-01, 2.25424767e-04, 2.90527344e-01]), array([8.7109375e-01, 1.1920929e-07, 1.2902832e-01]), array([7.48046875e-01, 2.38418579e-07, 2.52197266e-01]), array([7.75878906e-01, 1.01327896e-06, 2.23876953e-01]), array([8.65722656e-01, 2.56299973e-06, 1.34521484e-01]), array([0.59667969, 0.        , 0.40356445]), array([3.45703125e-01, 1.83582306e-05, 6.54296875e-01]), array([6.65527344e-01, 4.17232513e-07, 3.34472656e-01]), array([6.87500000e-01, 2.69651413e-04, 3.12255859e-01]), array([4.60449219e-01, 1.22189522e-05, 5.39550781e-01]), array([1.32202148e-01, 4.71591949e-04, 8.67187500e-01]), array([9.03808594e-01, 6.13927841e-06, 9.63745117e-02]), array([4.76318359e-01, 8.34465027e-06, 5.23925781e-01]), array([0.765625  , 0.03649902, 0.19763184]), array([1.59667969e-01, 2.30073929e-05, 8.40332031e-01]), array([4.70458984e-01, 3.45706940e-04, 5.29296875e-01]), array([9.09667969e-01, 1.19209290e-07, 9.03930664e-02]), array([0.96582031, 0.        , 0.03433228]), array([7.72949219e-01, 2.92539597e-04, 2.26562500e-01]), array([9.99511719e-01, 0.00000000e+00, 2.66790390e-04]), array([8.80371094e-01, 1.96695328e-06, 1.19567871e-01]), array([5.22460938e-01, 2.84433365e-04, 4.77539062e-01]), array([4.16748047e-01, 1.42216682e-04, 5.83007812e-01]), array([0.56298828, 0.00550461, 0.43164062]), array([7.01660156e-01, 6.55651093e-07, 2.98583984e-01]), array([7.89550781e-01, 3.07559967e-05, 2.10327148e-01]), array([5.52246094e-01, 1.79409981e-04, 4.47509766e-01]), array([0.96630859, 0.        , 0.03390503]), array([8.54492188e-01, 1.36971474e-04, 1.45385742e-01]), array([3.93554688e-01, 1.51395798e-05, 6.06445312e-01]), array([0.95263672, 0.        , 0.04714966]), array([7.35351562e-01, 1.46031380e-05, 2.64648438e-01]), array([7.04101562e-01, 9.53674316e-07, 2.95898438e-01]), array([0.1763916 , 0.0011673 , 0.82226562]), array([8.12988281e-01, 1.78813934e-07, 1.87011719e-01]), array([2.12768555e-01, 1.19209290e-07, 7.87109375e-01]), array([0.00277901, 0.        , 0.99707031]), array([3.01757812e-01, 9.47117805e-05, 6.98242188e-01]), array([4.80224609e-01, 6.42538071e-05, 5.19531250e-01]), array([0.58886719, 0.        , 0.41113281]), array([5.75195312e-01, 2.08258629e-04, 4.24316406e-01]), array([5.65429688e-01, 3.87430191e-04, 4.34082031e-01]), array([7.30957031e-01, 5.96046448e-08, 2.69287109e-01]), array([7.19547272e-04, 0.00000000e+00, 9.99511719e-01]), array([9.98046875e-01, 2.02655792e-06, 2.07519531e-03]), array([9.20410156e-01, 5.96046448e-08, 7.94067383e-02]), array([6.23046875e-01, 2.38418579e-07, 3.76953125e-01]), array([4.93408203e-01, 1.63316727e-04, 5.06347656e-01]), array([9.17968750e-01, 1.13248825e-06, 8.20312500e-02]), array([7.36816406e-01, 2.14576721e-04, 2.62939453e-01]), array([8.83789062e-01, 7.05242157e-04, 1.15356445e-01]), array([0.87890625, 0.        , 0.12115479]), array([0.74169922, 0.0007515 , 0.25732422]), array([6.11816406e-01, 1.20639801e-04, 3.88183594e-01]), array([9.38476562e-01, 2.98023224e-07, 6.16455078e-02]), array([9.01367188e-01, 1.13248825e-06, 9.88769531e-02]), array([7.32421875e-01, 8.26716423e-05, 2.67578125e-01]), array([0.96191406, 0.02348328, 0.01443481]), array([0.73046875, 0.        , 0.26953125]), array([7.34863281e-01, 2.02536583e-04, 2.65136719e-01]), array([8.30566406e-01, 3.45706940e-05, 1.69555664e-01]), array([1.10656738e-01, 5.96046448e-08, 8.89160156e-01]), array([8.94042969e-01, 1.19209290e-07, 1.05773926e-01]), array([1.73217773e-01, 1.19209290e-07, 8.26660156e-01]), array([0.95898438, 0.        , 0.04095459]), array([4.83642578e-01, 3.39746475e-06, 5.16113281e-01]), array([0.24511719, 0.        , 0.75488281]), array([0.89941406, 0.        , 0.10046387]), array([0.77636719, 0.        , 0.22351074]), array([0.91601562, 0.        , 0.08398438]), array([6.66503906e-01, 2.86102295e-06, 3.33251953e-01]), array([9.32128906e-01, 4.17232513e-07, 6.80541992e-02]), array([3.21777344e-01, 5.96046448e-07, 6.78222656e-01]), array([8.22753906e-01, 9.53674316e-06, 1.77124023e-01]), array([1.98211670e-02, 3.58819962e-04, 9.79980469e-01]), array([9.12109375e-01, 5.96046448e-08, 8.77075195e-02]), array([5.25878906e-01, 4.46438789e-05, 4.73876953e-01]), array([0.94189453, 0.        , 0.05834961]), array([5.48828125e-01, 1.10328197e-04, 4.51171875e-01]), array([8.35449219e-01, 5.96046448e-08, 1.64306641e-01]), array([0.52197266, 0.02806091, 0.45019531]), array([0.60693359, 0.00090265, 0.3918457 ]), array([9.57031250e-01, 5.96046448e-08, 4.31518555e-02]), array([9.31640625e-01, 1.78813934e-07, 6.86035156e-02]), array([6.73339844e-01, 8.94069672e-07, 3.26904297e-01]), array([0.88720703, 0.        , 0.1126709 ]), array([7.48535156e-01, 9.53674316e-06, 2.51708984e-01]), array([9.58496094e-01, 1.31130219e-06, 4.12597656e-02]), array([6.00585938e-01, 3.93390656e-04, 3.98925781e-01]), array([6.88964844e-01, 3.23057175e-05, 3.11035156e-01]), array([5.23925781e-01, 2.92062759e-06, 4.76074219e-01]), array([2.65869141e-01, 7.56978989e-06, 7.34375000e-01]), array([0.33032227, 0.        , 0.66943359]), array([0.25830078, 0.0008812 , 0.74072266]), array([0.91259766, 0.        , 0.08740234]), array([6.73828125e-01, 3.72409821e-04, 3.25683594e-01]), array([7.41210938e-01, 2.93850899e-05, 2.58544922e-01]), array([9.40917969e-01, 3.57627869e-07, 5.92651367e-02]), array([9.35058594e-01, 5.84125519e-06, 6.47583008e-02]), array([0.96044922, 0.        , 0.03979492]), array([4.54833984e-01, 1.78813934e-07, 5.44921875e-01]), array([8.80371094e-01, 9.53674316e-07, 1.19445801e-01]), array([7.62695312e-01, 5.32269478e-05, 2.37426758e-01]), array([7.12890625e-01, 2.82764435e-04, 2.86865234e-01]), array([0.61328125, 0.01194   , 0.37475586]), array([9.42871094e-01, 3.51667404e-06, 5.70068359e-02]), array([0.45996094, 0.01158905, 0.52832031]), array([5.35156250e-01, 1.31726265e-05, 4.64843750e-01]), array([9.59472656e-01, 4.46557999e-04, 4.00085449e-02]), array([7.03613281e-01, 3.45706940e-06, 2.96386719e-01]), array([5.80078125e-01, 5.96046448e-08, 4.19677734e-01]), array([5.92773438e-01, 1.82390213e-05, 4.07226562e-01]), array([7.8515625e-01, 2.9861927e-05, 2.1472168e-01]), array([8.67187500e-01, 1.78217888e-05, 1.32568359e-01]), array([9.01367188e-01, 1.72853470e-06, 9.84497070e-02]), array([0.86914062, 0.        , 0.13061523]), array([0.57568359, 0.07952881, 0.3449707 ]), array([4.28466797e-01, 1.99675560e-05, 5.71289062e-01]), array([9.08691406e-01, 1.78813934e-07, 9.13085938e-02]), array([0.39770508, 0.32543945, 0.27685547]), array([8.61328125e-01, 2.98023224e-07, 1.38671875e-01]), array([9.59472656e-01, 2.38418579e-07, 4.04968262e-02]), array([9.83886719e-01, 5.96046448e-08, 1.59912109e-02]), array([5.68359375e-01, 1.82747841e-04, 4.31396484e-01]), array([4.60937500e-01, 3.33786011e-06, 5.39062500e-01]), array([8.94531250e-01, 2.39014626e-05, 1.05407715e-01]), array([7.69042969e-01, 8.94069672e-07, 2.30712891e-01]), array([0.78417969, 0.00297546, 0.21289062]), array([0.63720703, 0.00121498, 0.36157227]), array([9.84497070e-02, 5.36441803e-07, 9.01367188e-01]), array([1.31225586e-02, 1.78813934e-07, 9.86816406e-01]), array([9.73144531e-01, 4.88758087e-06, 2.70080566e-02]), array([0.69580078, 0.00095272, 0.3034668 ]), array([4.43115234e-01, 1.07705593e-04, 5.56640625e-01]), array([9.56054688e-01, 5.96046448e-08, 4.39758301e-02]), array([0.87744141, 0.        , 0.12268066]), array([0.57910156, 0.        , 0.42089844]), array([5.30273438e-01, 7.27176666e-05, 4.69482422e-01]), array([7.44140625e-01, 5.01632690e-04, 2.55371094e-01]), array([0.25048828, 0.        , 0.74951172]), array([6.64550781e-01, 5.86509705e-04, 3.34716797e-01]), array([9.69238281e-01, 5.36441803e-07, 3.07312012e-02]), array([0.62207031, 0.00102139, 0.37670898]), array([0.43603516, 0.        , 0.56396484]), array([6.43310547e-02, 5.36441803e-07, 9.35546875e-01]), array([8.14453125e-01, 6.23464584e-05, 1.85546875e-01]), array([0.55273438, 0.00083923, 0.4465332 ]), array([0.07452393, 0.        , 0.92529297]), array([0.04559326, 0.        , 0.95458984]), array([0.5       , 0.00055933, 0.49951172]), array([8.41308594e-01, 2.09331512e-04, 1.58691406e-01]), array([0.73632812, 0.        , 0.26342773]), array([1.05590820e-02, 1.19209290e-07, 9.89257812e-01]), array([4.48730469e-01, 9.66787338e-05, 5.51269531e-01]), array([9.70214844e-01, 2.20537186e-06, 2.99835205e-02]), array([5.00000000e-01, 4.76241112e-05, 4.99755859e-01]), array([5.19531250e-01, 2.38418579e-07, 4.80712891e-01]), array([3.68164062e-01, 8.76188278e-06, 6.31835938e-01]), array([0.45556641, 0.11462402, 0.42993164]), array([9.98046875e-01, 3.15904617e-06, 2.17819214e-03]), array([5.20019531e-01, 6.55651093e-07, 4.79980469e-01]), array([8.97949219e-01, 1.99079514e-05, 1.01928711e-01]), array([7.34863281e-01, 3.57627869e-07, 2.65136719e-01]), array([4.85351562e-01, 2.74181366e-06, 5.14648438e-01]), array([5.68359375e-01, 2.78234482e-04, 4.31152344e-01]), array([0.8515625 , 0.        , 0.14868164]), array([5.52734375e-01, 2.31266022e-05, 4.47021484e-01]), array([7.69531250e-01, 4.76837158e-07, 2.30712891e-01]), array([5.15625000e-01, 3.14712524e-05, 4.84375000e-01]), array([5.42480469e-01, 1.35898590e-05, 4.57519531e-01]), array([5.93750000e-01, 1.70350075e-04, 4.06005859e-01]), array([9.10162926e-05, 0.00000000e+00, 1.00000000e+00]), array([0.99267578, 0.        , 0.00709152]), array([5.58593750e-01, 1.95980072e-04, 4.40917969e-01]), array([9.04296875e-01, 5.06639481e-06, 9.57031250e-02])]\n",
      "(300,) (300, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3704815433072474,\n",
       " 0.39866255144032925,\n",
       " 0.3626094265740001,\n",
       " 0.6335519279613879)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    exps = np.exp(x) \n",
    "    return exps / np.sum(exps, axis=0)\n",
    "\n",
    "from transformers import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "device = \"cuda:5\"\n",
    "model.to(device)\n",
    "\n",
    "epochs = 10\n",
    "count = 0\n",
    "pbar = tqdm(total = epochs * len(train_loader))\n",
    "for epoch in range(epochs):\n",
    "    pbar.set_description(f\"epoch: [{epoch+1}/{epochs}]\")\n",
    "    optimizer.zero_grad()\n",
    "    loss_train.reset()\n",
    "    for data in train_loader:\n",
    "        gpt_token, xlnet_token, glove_token, cbow_token, label = data\n",
    "        output = model(gpt_token['input_ids'].to(device), xlnet_token['input_ids'].to(device), glove_token.to(device), cbow_token.to(device))\n",
    "        loss = criterion(output, label.to(device))\n",
    "        loss_train.update(loss.cpu())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        pbar.update(1)\n",
    "        pbar.set_postfix({\"train loss\": loss_train.compute()})\n",
    "        count += 1\n",
    "\n",
    "        if count == 100:\n",
    "            break\n",
    "    break\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    loss_test.reset()\n",
    "    y_true = []\n",
    "    y_test = []\n",
    "    y_score = []\n",
    "    for data in valid_loader:\n",
    "        gpt_token, xlnet_token, glove_token, cbow_token, label = data\n",
    "        output = model(gpt_token['input_ids'].to(device), xlnet_token['input_ids'].to(device), glove_token.to(device), cbow_token.to(device))\n",
    "        sm = nn.Softmax(dim=-1)\n",
    "        output = sm(output).detach().cpu()\n",
    "        output = np.array(output)\n",
    "        y_test.extend(np.argmax(output, axis=1))\n",
    "        y_score.extend(output.astype('float64'))\n",
    "        y_true.extend(np.array(label))\n",
    "\n",
    "    print(y_test)\n",
    "    print(y_true)\n",
    "    print(y_score)\n",
    "    print(np.array(y_true).shape, np.array(y_score).shape)\n",
    "\n",
    "    f1 = f1_score(y_true=y_true, y_pred=y_test, average='macro')\n",
    "    recall = recall_score(y_true=y_true, y_pred=y_test, average='macro') \n",
    "    precision = precision_score(y_true=y_true, y_pred=y_test, average='macro') \n",
    "    y_score_normalized = np.array(y_score) / np.sum(y_score, axis=1, keepdims=True)\n",
    "    roc = roc_auc_score(y_true=y_true, y_score=y_score_normalized, average='macro', multi_class='ovr')\n",
    "\n",
    "f1, recall, precision, roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9375\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# y_true = [0, 1, 2, 0, 1, 2]\n",
    "# y_score = [\n",
    "#     [0.9, 0.1, 0.0],\n",
    "#     [0.2, 0.7, 0.1],\n",
    "#     [0.1, 0.3, 0.6],\n",
    "#     [0.8, 0.1, 0.1],\n",
    "#     [0.3, 0.4, 0.3],\n",
    "#     [0.2, 0.5, 0.3]\n",
    "# ]\n",
    "\n",
    "# auc = roc_auc_score(y_true, y_score, multi_class='ovr')\n",
    "# print(auc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
